{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linkedin Public Website Information Crawler/Spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import langchain as Langchain\n",
    "\n",
    "class Linkedin_Public_Spider(scrapy.Spider):\n",
    "    name = \"linkedin_company_profile\"\n",
    "\n",
    "    # Hier kommen alle öffentlichen LinkedIn-Seiten der Cryptofundraising-Seite hin, die mit einem anderen Crawler abgerufen werden\n",
    "    public_profile_webpages = [\n",
    "        'https://www.linkedin.com/company/kryptoskatt/about/',\n",
    "        # Weitere URLs hier hinzufügen\n",
    "    ]\n",
    "\n",
    "    custom_settings = {\n",
    "        'FEEDS': {\n",
    "            'Linkedin_public_profiles_output.csv': {\n",
    "                'format': 'csv',\n",
    "                'fields': ['name', 'summary', 'industry', 'size', 'founded'],\n",
    "            },\n",
    "        },\n",
    "        'DOWNLOADER_MIDDLEWARES': {\n",
    "            'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware': None,\n",
    "            'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware': None,\n",
    "            'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware': None,\n",
    "            'scrapy.downloadermiddlewares.retry.RetryMiddleware': None,\n",
    "            'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware': None,\n",
    "            'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware': None,\n",
    "            'scrapy.downloadermiddlewares.cookies.CookiesMiddleware': None,\n",
    "            'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware': None,\n",
    "            'scrapy.downloadermiddlewares.stats.DownloaderStats': None,\n",
    "            'scrapy_user_agents.middlewares.RandomUserAgentMiddleware': 400,\n",
    "            'scrapy_proxies.RandomProxy': 100,\n",
    "            'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware': 110,\n",
    "        },\n",
    "        'USER_AGENT_LIST': 'path/to/user_agent_list.txt',  # Pfad zur Datei mit User-Agent-Liste\n",
    "        'RETRY_TIMES': 5,  # Anzahl der Wiederholungsversuche bei Fehlern\n",
    "        'PROXY_POOL_ENABLED': True,  # Aktiviert die Verwendung von Proxies\n",
    "        'REQUEST_FINGERPRINTER_IMPLEMENTATION': 'scrapy.utils.request.fingerprint.request_fingerprint',\n",
    "    }\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.langchain = Langchain(api_key='YOUR_API_KEY', endpoint='YOUR_API_ENDPOINT')\n",
    "\n",
    "    def start_requests(self):\n",
    "        for index, url in enumerate(self.public_profile_webpages):\n",
    "            yield scrapy.Request(url=url, callback=self.parse_response, meta={'public_profile_index': index})\n",
    "\n",
    "    def parse_response(self, response):\n",
    "        public_profile_index = response.meta['public_profile_index']\n",
    "        print('***************')\n",
    "        print('****** Scraping page ' + str(public_profile_index+1) + ' of ' + str(len(self.public_profile_webpages)))\n",
    "        print('***************')\n",
    "\n",
    "        firmen_items = {}\n",
    "\n",
    "        # Extrahieren der gewünschten Informationen\n",
    "        firmen_items['name'] = response.css('.top-card-layout__entity-info h1::text').get(default='not-found').strip()\n",
    "        firmen_items['summary'] = response.css('.top-card-layout__entity-info h4 span::text').get(default='not-found').strip()\n",
    "\n",
    "        try:\n",
    "            firmen_details = response.css('.core-section-container__content .mb-2')\n",
    "\n",
    "            firma_branchentyp = firmen_details[1].css('.text-md::text').getall()\n",
    "            firmen_items['industry'] = firma_branchentyp[1].strip()\n",
    "\n",
    "            größe_der_firma = firmen_details[2].            größe_der_firma = firmen_details[2].css('.text-md::text').getall()\n",
    "            firmen_items['size'] = größe_der_firma[1].strip()\n",
    "\n",
    "            gründung_der_firma = firmen_details[5].css('.text-md::text').getall()\n",
    "            firmen_items['founded'] = gründung_der_firma[1].strip()\n",
    "        \n",
    "        except IndexError:\n",
    "            print(\"Error: Firma wurde ausgelassen - Einige Infos fehlen!\")\n",
    "\n",
    "        # Konvertieren des firmen_items in JSON\n",
    "        firmen_json = json.dumps(firmen_items)\n",
    "\n",
    "        # Aufrufen der Langchain-API für die Analyse\n",
    "        analysis = self.langchain.analyze(firmen_json)\n",
    "\n",
    "        # Extrahieren der analysierten Informationen\n",
    "        sentiment = analysis['sentiment']\n",
    "        entities = analysis['entities']\n",
    "        keywords = analysis['keywords']\n",
    "\n",
    "        # Hinzufügen der analysierten Informationen zu firmen_items\n",
    "        firmen_items['sentiment'] = sentiment\n",
    "        firmen_items['entities'] = entities\n",
    "        firmen_items['keywords'] = keywords\n",
    "\n",
    "        yield firmen_items\n",
    "\n",
    "        public_profile_index = public_profile_index + 1\n",
    "\n",
    "        if public_profile_index < len(self.public_profile_webpages):\n",
    "            next_url = self.public_profile_webpages[public_profile_index]\n",
    "            time.sleep(20)  # Verzögerung von 20 Sekunden einfügen\n",
    "            yield scrapy.Request(url=next_url, callback=self.parse_response, meta={'public_profile_index': public_profile_index})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im Terminal:\n",
    "# 1) Folder erstellen:\n",
    "# cd \"C:\\Users\\Engineer\\OneDrive - DataCraft GmbH\\Dokumente\\DataCraft\\4.1. Vorbereitung Praxis\\Webcrawler\"\n",
    "\n",
    "# 2) Scrapy Projekt anlegen\n",
    "# scrapy startproject Linkedin_Firmeninfos_public\n",
    "\n",
    "# 3) in Projektverzeichnis navigieren:\n",
    "# cd Linkedin_Firmeninfos_public\n",
    "# Wenn Projekt schon angelegt ist, dann:\n",
    "# cd C:\\Users\\Engineer\\\"OneDrive - DataCraft GmbH\"\\Dokumente\\DataCraft\\\"4.1. Vorbereitung Praxis\"\\Webcrawler\\Linkedin_Firmen_infos\n",
    "\n",
    "# 4) Spider erstellen\n",
    "# scrapy genspider Linkedin_Public_Spider linkedin.com\n",
    "\n",
    "# 5) Spider laufen lassen\n",
    "# scrapy runspider Linkedin_Public_Spider.py\n",
    "# mit output als csv:\n",
    "# scrapy runspider Linkedin_Public_Spider.py -o Linkedin_public_profiles_output.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brauche Langchain, um nicht geblockt zu werden:\n",
    "# Terminal: pip install langchain\n",
    "# API ist kostenpflichtig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
